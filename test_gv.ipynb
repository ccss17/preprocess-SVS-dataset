{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from rich import print as rprint\n",
    "import midii\n",
    "\n",
    "import preprocess_svs as ps\n",
    "from preprocess_svs import gv, SVS_Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GV File Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_path = \"D:/dataset/177.다음색 가이드보컬 데이터\"\n",
    "gv_json_sample = \"sample/gv/json\"\n",
    "gv_mid_sample = \"sample/gv/midi\"\n",
    "gv_sample_preprocessed = \"sample/gv/json_preprocessed\"\n",
    "gv_json_time_adjusted = \"D:/dataset/다음색 가이드보컬 데이터 time_adjusted\"\n",
    "gv_json_preprocessed = \"D:/dataset/다음색 가이드보컬 데이터 json preprocessed\"\n",
    "midi_filepath = \"sample/gv/midi/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.mid\"\n",
    "time_adjusted_json_filepath = \"sample/gv/json_time_adjusted/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\"\n",
    "filled_time_gaps_json_filepath = \"sample/gv/json_filled_time_gaps/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3605\n"
     ]
    }
   ],
   "source": [
    "print(len(list(ps.get_files(gv_path, \"mid\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(857142, 790)]\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "mid = midii.MidiFile(midi_filepath, convert_1_to_0=True)\n",
    "tempo_rank = mid.tempo_rank()\n",
    "print(tempo_rank)\n",
    "print(ps.calculate_top_tempo_percentage(tempo_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Tempo Deviation\n",
    "\n",
    "- json 을 처리하려면 quantize 를 위한 tempo 가 필요한데 json 에는 tempo 정보가 없음 \n",
    "- -> tempo rank 검사 \n",
    "- -> tempo 가 변하지 않는다는 충분한 보장\n",
    "- -> dominate tempo 를 채택하여 quantize 해도 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps.tempo_statistics(gv_path, parallel=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- -> 이전 end_time 이 현재 start_time 보다 큰 경우가 있음 \n",
    "- -> 이전 end_time 에 현재 start_time 을 맞추면, 뒤따라오는 메시지들의 sync 가 다 틀어짐 \n",
    "- -> 이전 end_time 을 현재 start_time 에 맞춰주는 게 더 나음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify notes sorted by time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gv.verify_json_notes_sorted_by_time(gv_path, parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_note_times_sample():\n",
    "    gv_path = \"sample/gv/json\"\n",
    "    for json_path in ps.get_files(gv_path, \"json\"):\n",
    "        p_orig = Path(json_path)\n",
    "        out_path = p_orig.parent.parent / \"json_time_adjusted\" / p_orig.name\n",
    "        out_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        print(f\"adjust time of \\n{json_path}\")\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        notes = data.get(\"notes\")\n",
    "        processed_notes = gv.adjust_note_times(notes)\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(processed_notes, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"saved to \\n{out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adjust time of \n",
      "sample\\gv\\json\\SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\n",
      "saved to \n",
      "sample\\gv\\json_time_adjusted\\SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\n",
      "adjust time of \n",
      "sample\\gv\\json\\SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835.json\n",
      "saved to \n",
      "sample\\gv\\json_time_adjusted\\SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835.json\n"
     ]
    }
   ],
   "source": [
    "adjust_note_times_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill silence note between notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample/gv/json_time_adjusted/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\n",
      "sample/gv/json_filled_time_gaps/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\n"
     ]
    }
   ],
   "source": [
    "print(time_adjusted_json_filepath)\n",
    "print(filled_time_gaps_json_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save:\n",
      "sample\\gv\\json_filled_time_gaps\\SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\n"
     ]
    }
   ],
   "source": [
    "gv.fill_time_gaps_save(time_adjusted_json_filepath, filled_time_gaps_json_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify correspondence json vs wav vs mid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">([]</span>, <span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">([]</span>, <span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">([]</span>, <span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jsons = ps.get_files(gv_path, \"json\", sort=True)\n",
    "mids = ps.get_files(gv_path, \"mid\", sort=True)\n",
    "wavs = ps.get_files(gv_path, \"wav\", sort=True)\n",
    "rprint(gv.verify_files_coherent(jsons, mids))\n",
    "rprint(gv.verify_files_coherent(wavs, mids))\n",
    "rprint(gv.verify_files_coherent(jsons, wavs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove abnormal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv.remove_abnormal_file(gv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GV Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filepath = \"sample/gv/json_preprocessed/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\"\n",
    "split_json_filepath = \"sample/gv/split_json/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.json\"\n",
    "preprocessed_gv_path = \"preprocessed_gv/\"\n",
    "preprocessed_gv_duration_path = \"preprocessed_gv/duration\"\n",
    "preprocessed_gv_pitch_path = \"preprocessed_gv/pitch\"\n",
    "preprocessed_gv_wav_path = \"preprocessed_gv/wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - preprocess gv json\n",
    "\n",
    "- gv json -> adjust note times + fill time gaps + quantization + frames\n",
    "- embed coherent json format(sharing with mssv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample/gv/json sample/gv/midi sample/gv/json_preprocessed\n"
     ]
    }
   ],
   "source": [
    "print(gv_json_sample, gv_mid_sample, gv_sample_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.preprocess_json(\n",
    "    gv_json_sample, gv_mid_sample, gv_sample_preprocessed, parallel=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gv.preprocess_json(\n",
    "#     gv_path,\n",
    "#     gv_path,\n",
    "#     gv_json_preprocessed,\n",
    "#     parallel=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - split notes by silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_json = ps.split_json_by_silence(json_filepath, min_length=6)\n",
    "# split_json_filepath = Path(split_json_filepath)\n",
    "# split_json_filepath.parent.mkdir(exist_ok=True, parents=True)\n",
    "# with open(split_json_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(split_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.split_json(json_filepath, split_json_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dirpath = 'sample/gv/json_preprocessed'\n",
    "split_json_dirpath = 'sample/gv/split_json'\n",
    "ps.split_jsons(json_dirpath, split_json_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - save duration, pitch as npy file, split audio, save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_filepath = \"sample/gv/wav/SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_list = []\n",
    "metadata_list.append(\n",
    "    ps.preprocess_one(\n",
    "        wav_filepath,\n",
    "        split_json_filepath,\n",
    "        preprocessed_gv_path,\n",
    "        singer_id_from_filepath=gv.singer_id_from_filepath\n",
    "    )\n",
    ")\n",
    "preprocessed_gv_path = Path(preprocessed_gv_path)\n",
    "preprocessed_gv_path.mkdir(exist_ok=True, parents=True)\n",
    "with open(f\"{preprocessed_gv_path}/metadata.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\".join(metadata_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dirpath = 'sample/gv/wav/'\n",
    "split_json_dirpath = 'sample/gv/split_json/'\n",
    "ps.save_duration_pitch_metadata_split_audio(\n",
    "    wav_dirpath,\n",
    "    split_json_dirpath,\n",
    "    preprocessed_gv_path,\n",
    "    singer_id_from_filepath=gv.singer_id_from_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizer 사용 설명\n",
    "\n",
    "### 1. lyric_normalizer.py의 LyricNormalizer 클래스 import\n",
    "### 2. LyricNormalizer 객체 생성\n",
    "### 3. LyricNormalizer.normalize_lyrics() 함수 사용\n",
    "#### &emsp; Input: GT(whisper result), 원본 가사, pitch sequence, duration sequence\n",
    "#### &emsp; Output: 정규화 가사, pitch sequence, duration sequence, 정규화 정보를 담은 dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SVS_Preprocessor(\n",
    "    base_path=\"preprocessed_gv\",\n",
    "    model_name=\"tiny\",\n",
    "    device=\"cpu\",\n",
    "    language=\"ko\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chans\\repo\\preprocess-SVS\\.venv\\Lib\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in DTW: gt_text: 사랑에나요나보다도내가는그녀와있는니\n",
      "raw_text: 사아라앙해앤나요오나아보오다도오내애가아아니인그으녀어와이인느은니이\n",
      "DTW 행렬의 위치 [0, 26]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 난어느새보고많이싸서믿을수없어\n",
      "raw_text: 나아너어느새애보오고오마니이써어써어미이들수우업써어\n",
      "DTW 행렬의 위치 [0, 12]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error2 in normalize_lyric: list index out of range\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 좀늦은것같아우리그녀를너무많이사랑해보였\n",
      "raw_text: 초옴느으즌거어까아타아우리이그으녀르을너무우마니이사아라앙해애보오여어\n",
      "DTW 행렬의 위치 [0, 25]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 하늘너머로모든추워보도록자말리로널떠나보내게\n",
      "raw_text: 하아느을너어머어로오모드으은추우억모오두우저어멀리이로오널떠어나보오내앨께에\n",
      "DTW 행렬의 위치 [0, 24]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 눈을가면돼이제내눈가대보이는그대모셔비\n",
      "raw_text: 누우느을가아암느은다아이제에엔내누운가드윽보오이느은그으대모오스비이\n",
      "DTW 행렬의 위치 [0, 23]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error2 in normalize_lyric: list index out of range\n",
      "error in normalized!\n",
      "Error2 in normalize_lyric: list index out of range\n",
      "error in normalized!\n",
      "Error2 in normalize_lyric: list index out of range\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 좀늦은것같아우리그녀를\n",
      "raw_text: 조옴느으즌거어까아타아우리이그으녀\n",
      "DTW 행렬의 위치 [0, 8]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 모든초웅모드짜말리로늘떠나보낼게\n",
      "raw_text: 모드으은추우억모오두우저어멀리이로오널떠어나보오내앨께에\n",
      "DTW 행렬의 위치 [0, 12]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 눈을감는다이제내눈가닥보이는그대모습이\n",
      "raw_text: 누우느을가아암느은다아이제에엔내누운가드윽보오이느은그으대모오스비이\n",
      "DTW 행렬의 위치 [0, 27]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 아나와요\n",
      "raw_text: 너어무미이워어서어\n",
      "DTW 행렬의 위치 [0, 10]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 나는왜나를봐주지않는지넌넌\n",
      "raw_text: 너어느은왜나아를봐아주우지이않느은지이너어너어너어\n",
      "DTW 행렬의 위치 [0, 18]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 특별한래게바라지는마설레이문래게바라지는마하지만내게하지만내게날보여줄수있게\n",
      "raw_text: 특별하암을내애게에바아라지이느은마아설레에이이므을내애게에바아라지이느은마하지이마안내애애게에하지이마안내애애게에날보오여주울쑤우있게에\n",
      "DTW 행렬의 위치 [0, 48]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 우리의만나문특별해\n",
      "raw_text: 어어우우리이의마안나아므은트윽벼얼해애\n",
      "DTW 행렬의 위치 [0, 3]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 우리의만나면사랑해나는왜나는왜\n",
      "raw_text: 우우리이의마안나아므은사아라앙해애나느은왜나느은왜애\n",
      "DTW 행렬의 위치 [0, 10]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 우린다갈수있나왜또나는내게왜일이날거래왜또\n",
      "raw_text: 우우리인다아가알쑤우이있나아왜애또오너어는내애게에왜이리이달코옴해애왜애또오\n",
      "DTW 행렬의 위치 [0, 19]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 너는내게왜일이사랑해왜또너는내게\n",
      "raw_text: 너어는내애게에왜이리이사아라앙해애왜애또오너어는내애게에왜\n",
      "DTW 행렬의 위치 [0, 23]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 또너는내게베일이찰라내왜또나는너를베일이다장해왜또\n",
      "raw_text: 애또오너어는내애게에왜이리이찬라안해애왜애또오나아는너어르을왜이리이다아저엉해애왜애또오\n",
      "DTW 행렬의 위치 [0, 29]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 너는내게왜이리새콤해왜또나는나를왜또나는내게\n",
      "raw_text: 너어는내애게에왜이리이새코옴해애왜애또오나아는너어르을왜애또오너어는내애게에\n",
      "DTW 행렬의 위치 [0, 28]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 베일이달콤해왜또너는내게베일이사랑해\n",
      "raw_text: 왜이리이달코옴해애왜애또오너어는내애게에왜이리이사아라앙해애왜애\n",
      "DTW 행렬의 위치 [0, 20]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 또나는내게베일이다의꿈에또나는내게\n",
      "raw_text: 또오너는내애게에왜이리이달코옴해애왜애또오너어는내애게에\n",
      "DTW 행렬의 위치 [0, 18]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "Error in DTW: gt_text: 왜또너는내게왜일이찰라내왜또나는너를\n",
      "raw_text: 왜애또오너어는내애게에왜이리이찬라안해애왜애또오나아는너어르을\n",
      "DTW 행렬의 위치 [0, 10]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n",
      "error in normalized!\n",
      "running step 4 Done.\n",
      "\n",
      "\n",
      "Starting dataset verification...\n",
      "\n",
      "=== Starting Dataset Consistency Verification ===\n",
      "\n",
      "=== Verification Results ===\n",
      "\n",
      "Errors found:\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_00: Length mismatch - lyrics(35), pitch(21), duration(21)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_01: Length mismatch - lyrics(25), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_02: Length mismatch - lyrics(27), pitch(16), duration(16)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_03: Length mismatch - lyrics(24), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_04: Length mismatch - lyrics(24), pitch(14), duration(14)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_05: Length mismatch - lyrics(37), pitch(23), duration(23)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_06: Length mismatch - lyrics(40), pitch(25), duration(25)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_07: Length mismatch - lyrics(35), pitch(21), duration(21)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_08: Length mismatch - lyrics(26), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_10: Length mismatch - lyrics(20), pitch(12), duration(12)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_11: Length mismatch - lyrics(27), pitch(16), duration(16)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_12: Length mismatch - lyrics(24), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_13: Length mismatch - lyrics(24), pitch(14), duration(14)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_00: Length mismatch - lyrics(33), pitch(26), duration(26)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_03: Length mismatch - lyrics(40), pitch(26), duration(26)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_04: Length mismatch - lyrics(39), pitch(25), duration(25)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_15: Length mismatch - lyrics(34), pitch(28), duration(28)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_16: Length mismatch - lyrics(9), pitch(8), duration(8)\n",
      "\n",
      "No warnings!\n",
      "\n",
      "WARNING: Dataset verification found errors!\n",
      "Please check the errors above and fix them before proceeding.\n"
     ]
    }
   ],
   "source": [
    "preprocessor.process_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Dataset Consistency Verification ===\n",
      "\n",
      "=== Verification Results ===\n",
      "\n",
      "Errors found:\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_00: Length mismatch - lyrics(35), pitch(21), duration(21)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_01: Length mismatch - lyrics(25), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_02: Length mismatch - lyrics(27), pitch(16), duration(16)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_03: Length mismatch - lyrics(24), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_04: Length mismatch - lyrics(24), pitch(14), duration(14)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_05: Length mismatch - lyrics(37), pitch(23), duration(23)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_06: Length mismatch - lyrics(40), pitch(25), duration(25)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_07: Length mismatch - lyrics(35), pitch(21), duration(21)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_08: Length mismatch - lyrics(26), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_10: Length mismatch - lyrics(20), pitch(12), duration(12)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_11: Length mismatch - lyrics(27), pitch(16), duration(16)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_12: Length mismatch - lyrics(24), pitch(15), duration(15)\n",
      "- SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_13: Length mismatch - lyrics(24), pitch(14), duration(14)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_00: Length mismatch - lyrics(33), pitch(26), duration(26)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_03: Length mismatch - lyrics(40), pitch(26), duration(26)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_04: Length mismatch - lyrics(39), pitch(25), duration(25)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_15: Length mismatch - lyrics(34), pitch(28), duration(28)\n",
      "- SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_16: Length mismatch - lyrics(9), pitch(8), duration(8)\n",
      "\n",
      "No warnings!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'errors': ['SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_00: Length mismatch - lyrics(35), pitch(21), duration(21)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_01: Length mismatch - lyrics(25), pitch(15), duration(15)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_02: Length mismatch - lyrics(27), pitch(16), duration(16)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_03: Length mismatch - lyrics(24), pitch(15), duration(15)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_04: Length mismatch - lyrics(24), pitch(14), duration(14)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_05: Length mismatch - lyrics(37), pitch(23), duration(23)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_06: Length mismatch - lyrics(40), pitch(25), duration(25)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_07: Length mismatch - lyrics(35), pitch(21), duration(21)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_08: Length mismatch - lyrics(26), pitch(15), duration(15)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_10: Length mismatch - lyrics(20), pitch(12), duration(12)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_11: Length mismatch - lyrics(27), pitch(16), duration(16)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_12: Length mismatch - lyrics(24), pitch(15), duration(15)',\n",
       "  'SINGER_16_10TO29_CLEAR_FEMALE_BALLAD_C0632_13: Length mismatch - lyrics(24), pitch(14), duration(14)',\n",
       "  'SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_00: Length mismatch - lyrics(33), pitch(26), duration(26)',\n",
       "  'SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_03: Length mismatch - lyrics(40), pitch(26), duration(26)',\n",
       "  'SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_04: Length mismatch - lyrics(39), pitch(25), duration(25)',\n",
       "  'SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_15: Length mismatch - lyrics(34), pitch(28), duration(28)',\n",
       "  'SINGER_66_30TO49_HUSKY_MALE_DANCE_C2835_16: Length mismatch - lyrics(9), pitch(8), duration(8)'],\n",
       " 'warnings': []}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.verify_dataset_consistency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply G2pk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'preprocessed_gv/normalized_metadata.txt'\n",
    "ps.g2p_metadata(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
