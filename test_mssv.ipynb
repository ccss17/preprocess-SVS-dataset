{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from rich import print as rprint\n",
    "import numpy as np\n",
    "import whisper\n",
    "from rich import print as rprint\n",
    "import midii\n",
    "\n",
    "import preprocess_svs as ps \n",
    "from preprocess_svs import mssv \n",
    "from preprocess_svs import LyricNormalizer, SVS_Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSSV File Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mssv_path = \"D:/dataset/004.다화자 가창 데이터\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">967742</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">593</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1250000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">983607</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1016949</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1034483</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1052632</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1071429</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1090909</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1111111</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1132075</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1153846</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1176471</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1200000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1224490</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1276596</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1304348</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1333333</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1363636</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1395349</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1428571</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1463415</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1500000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1538462</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1578947</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1621622</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1666667</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1714286</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1764706</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1818182</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1875000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1935484</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m967742\u001b[0m, \u001b[1;36m593\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1250000\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m300000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m983607\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1000000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1016949\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1034483\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1052632\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1071429\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1090909\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1111111\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1132075\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1153846\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1176471\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1200000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1224490\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1276596\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1304348\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1333333\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1363636\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1395349\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1428571\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1463415\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1500000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1538462\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1578947\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1621622\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1666667\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1714286\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1764706\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1818182\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1875000\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1m(\u001b[0m\u001b[1;36m1935484\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">94.72843450479233</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m94.72843450479233\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_mssv_midi = \"sample/mssv/midi/ba_05688_-4_a_s02_m_02.mid\"\n",
    "mid = midii.MidiFile(sample_mssv_midi, convert_1_to_0=True)\n",
    "tempo_rank = mid.tempo_rank()\n",
    "rprint(tempo_rank)\n",
    "rprint(ps.calculate_top_tempo_percentage(tempo_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Tempo Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps.tempo_statistics(mssv_path, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- --> MSSV 데이터셋의 tempo 의 편차가 커서, ticks 단위에서 음표 길이 정규화를 해야 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify notes sorted by time\n",
    "\n",
    "- mssv 의 json 은 MIDI 에서 직접 변환했으므로 time 정렬이 본질적으로 내재되어 있으므로 이 단계를 skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fill silence note between notes\n",
    "\n",
    "- mssv 의 json 은 MIDI 에서 변환하는 과정에서 notes 사이에 공백을 채웠음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verify correspondence wav vs mid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(mssv.find_exclusive_two_type_files(\"*.mid\", \"*.wav\", mssv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check abnormal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(mssv.check_abnormal_file(mssv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename abnormal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">({}</span>, <span style=\"font-weight: bold\">{})</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(mssv.rename_abnormal_file(mssv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove abnormal files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">([]</span>, <span style=\"font-weight: bold\">[])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rprint(mssv.remove_abnormal_file(mssv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify midi pattern(on-lyrics-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mssv.verify_midi_files_pattern_on_lyrics_off(mssv_path, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify lyrics has no time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mssv.verify_midi_files_lyrics_has_no_time(mssv_path, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSSV Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_filepath = \"sample/mssv/midi/ba_05688_-4_a_s02_m_02.mid\"\n",
    "wav_filepath = \"sample/mssv/wav/ba_05688_-4_a_s02_m_02.wav\"\n",
    "json_filepath = \"sample/mssv/json/ba_05688_-4_a_s02_m_02.json\"\n",
    "split_json_filepath = \"sample/mssv/split_json/ba_05688_-4_a_s02_m_02.json\"\n",
    "preprocessed_mssv_path = \"preprocessed_mssv/\"\n",
    "preprocessed_mssv_duration_path = \"preprocessed_mssv/duration\"\n",
    "preprocessed_mssv_pitch_path = \"preprocessed_mssv/pitch\"\n",
    "preprocessed_mssv_wav_path = \"preprocessed_mssv/wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - midi to json \n",
    "\n",
    "- note duration quantization\n",
    "- duration conversion [ticks --> seconds -> frames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_dirpath = 'sample/mssv/midi'\n",
    "json_dirpath = 'sample/mssv/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mssv.midis_to_jsons(midi_dirpath, json_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - split notes by silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_json = ps.split_json_by_silence(json_filepath, min_length=6)\n",
    "# split_json_filepath = Path(split_json_filepath)\n",
    "# split_json_filepath.parent.mkdir(exist_ok=True, parents=True)\n",
    "# with open(split_json_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(split_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mssv.split_json(json_filepath, split_json_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_json_dirpath = 'sample/mssv/split_json'\n",
    "mssv.split_jsons(json_dirpath, split_json_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - save duration, pitch as npy file, split audio, save metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_list = []\n",
    "metadata_list.append(\n",
    "    mssv.preprocess_one(\n",
    "        wav_filepath,\n",
    "        split_json_filepath,\n",
    "        preprocessed_mssv_pitch_path,\n",
    "        preprocessed_mssv_duration_path,\n",
    "        preprocessed_mssv_wav_path,\n",
    "    )\n",
    ")\n",
    "with open(f\"{preprocessed_mssv_path}/metadata.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\".join(metadata_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dirpath = 'sample/mssv/wav/'\n",
    "split_json_dirpath = 'sample/mssv/split_json/'\n",
    "mssv.save_duration_pitch_metadata_split_audio(\n",
    "    wav_dirpath,\n",
    "    split_json_dirpath,\n",
    "    preprocessed_mssv_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizer 사용 설명\n",
    "\n",
    "### 1. lyric_normalizer.py의 LyricNormalizer 클래스 import\n",
    "### 2. LyricNormalizer 객체 생성\n",
    "### 3. LyricNormalizer.normalize_lyrics() 함수 사용\n",
    "#### &emsp; Input: GT(whisper result), 원본 가사, pitch sequence, duration sequence\n",
    "#### &emsp; Output: 정규화 가사, pitch sequence, duration sequence, 정규화 정보를 담은 dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SVS_Preprocessor(\n",
    "    base_path=\"preprocessed_mssv\",\n",
    "    model_name=\"large-v3\",\n",
    "    device=\"cpu\",\n",
    "    language=\"ko\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in DTW: gt_text: 했는데이젠마음이변해버렸나\n",
      "raw_text: 했는데이젠맘이변해버렸나\n",
      "DTW 행렬의 위치 [3, 0]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in DTW: gt_text: 이별이그리쉬운가\n",
      "raw_text: 아이별이그리쉬운가\n",
      "DTW 행렬의 위치 [0, 1]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in DTW: gt_text: 이별이그리쉬운가\n",
      "raw_text: 아이별이그리쉬운가\n",
      "DTW 행렬의 위치 [0, 1]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in DTW: gt_text: 모두가떠난다고여보내손을꼭잡았어\n",
      "raw_text: 모두가떠어난다고여보내손을꼭잡았소오\n",
      "DTW 행렬의 위치 [0, 4]에서 잘못된 경로 정보를 발견했습니다. 2개의 정수로 구성된 튜플이 필요하지만, 다음을 받았습니다: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/ccsss/repo/preprocess-svs-dataset/.venv/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing normalized metadata to: preprocessed_mssv/metadata.txt\n",
      "Done.\n",
      "\n",
      "Starting dataset verification...\n",
      "\n",
      "=== Starting Dataset Consistency Verification ===\n",
      "\n",
      "=== Verification Results ===\n",
      "\n",
      "No errors found!\n",
      "\n",
      "No warnings!\n",
      "\n",
      "Dataset verification completed successfully!\n"
     ]
    }
   ],
   "source": [
    "preprocessor.process_all_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Dataset Consistency Verification ===\n",
      "\n",
      "=== Verification Results ===\n",
      "\n",
      "No errors found!\n",
      "\n",
      "No warnings!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'errors': [], 'warnings': []}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.verify_dataset_consistency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply G2pk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n",
      "mecab installed\n"
     ]
    }
   ],
   "source": [
    "file_path = 'preprocessed_mssv/metadata.txt'\n",
    "ps.g2p_metadata(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
